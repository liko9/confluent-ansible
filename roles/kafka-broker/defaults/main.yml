kafka:
  broker:
    user: cp-kafka
    group: confluent
    config_file: /etc/kafka/server.properties
    logging_config_file: /etc/kafka/server.logging.properties
    #    systemd_file: /usr/lib/systemd/system/confluent-kafka.service
    service_name: confluent-kafka
    datadir:
      - /var/lib/kafka
    environment:
      KAFKA_HEAP_OPTS: "-Xmx1000M"
      LOG_DIR: /var/log/kafka
    systemd:
      enabled: yes
      state: started
      LimitNOFILE: 128000
      TimeoutStopSec: 300
      RestartSec: 5
    config:
      confluent.support.customer.id: anonymous
      confluent.support.metrics.enable: true
      group.initial.rebalance.delay.ms: 0
      log.retention.check.interval.ms: 300000
      log.retention.hours: 168
      log.segment.bytes: 1073741824
      num.io.threads: 16
      num.network.threads: 8
      num.partitions: 1
      num.recovery.threads.per.data.dir: 2
      offsets.topic.replication.factor: 3
      socket.receive.buffer.bytes: 102400
      socket.request.max.bytes: 104857600
      socket.send.buffer.bytes: 102400
      transaction.state.log.min.isr: 2
      transaction.state.log.replication.factor: 3
      zookeeper.connection.timeout.ms: 6000
      metric.reporters: io.confluent.metrics.reporter.ConfluentMetricsReporter
      confluent.metrics.reporter.bootstrap.servers: "{{inventory_hostname}}:9092"
